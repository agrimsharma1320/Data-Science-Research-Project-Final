{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AXFKqEKRLjby"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "#df = pd.read_csv(\"reddit_mh_parallel_preprocessed-2.csv\")\n",
        "\n",
        "# Remove rows where 'selftext' is NaN or empty string\n",
        "#df = df.dropna(subset=['selftext'])\n",
        "#df = df[df['selftext'].str.strip() != \"\"]\n",
        "\n",
        "#df.to_csv(\"reddit_mh_parallel_cleaned.csv\", index=False)\n",
        "\n",
        "#print(f\"Remaining rows after cleaning: {len(df)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2d376615",
        "outputId": "09e860c1-138d-4fb2-c80c-3c3280421686"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of missing 'selftext' values in the cleaned dataset: 0\n",
            "Number of empty 'selftext' strings in the cleaned dataset: 0\n",
            "Integrity check passed: No missing or empty 'selftext' values found.\n"
          ]
        }
      ],
      "source": [
        "# Load the cleaned dataset\n",
        "df_cleaned = pd.read_csv(\"reddit_mh_parallel_cleaned.csv\")\n",
        "\n",
        "# Check for missing values in the 'selftext' column\n",
        "missing_selftext = df_cleaned['selftext'].isnull().sum()\n",
        "\n",
        "print(f\"Number of missing 'selftext' values in the cleaned dataset: {missing_selftext}\")\n",
        "\n",
        "# Additionally, check for empty strings in 'selftext'\n",
        "empty_selftext = (df_cleaned['selftext'].astype(str).str.strip() == \"\").sum()\n",
        "\n",
        "print(f\"Number of empty 'selftext' strings in the cleaned dataset: {empty_selftext}\")\n",
        "\n",
        "if missing_selftext == 0 and empty_selftext == 0:\n",
        "    print(\"Integrity check passed: No missing or empty 'selftext' values found.\")\n",
        "else:\n",
        "    print(\"Integrity check failed: Missing or empty 'selftext' values found.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7bD-ORwY4q4b"
      },
      "outputs": [],
      "source": [
        "!pip -q install transformers accelerate datasets scikit-learn torch --upgrade\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yy3T2lIz5ADy",
        "outputId": "7eb5a66d-6ce1-4fca-aa15-4f805fd12bdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(18779, 13) ['id', 'title', 'selftext', 'created_utc', 'num_comments', 'score', 'subreddit', 'author', 'url', 'comments', 'processed_title', 'processed_selftext', 'processed_comments']\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "PATH = \"reddit_mh_parallel_cleaned.csv\"   # your cleaned file\n",
        "TEXT_COL = \"selftext\"                                # change to 'processed_selftext' if needed\n",
        "\n",
        "df = pd.read_csv(PATH)\n",
        "df = df.dropna(subset=[TEXT_COL])\n",
        "df[TEXT_COL] = df[TEXT_COL].astype(str).str.strip()\n",
        "df = df[df[TEXT_COL] != \"\"].reset_index(drop=True)\n",
        "print(df.shape, df.columns.tolist()[:15])\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}